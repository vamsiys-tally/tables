{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to env (Python 3.11.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4893a99b-fa16-42fd-a5be-5942422d532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pdfplumber as plumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c7b2c5-4c4e-4df9-b282-5fa4749948e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Cell:\n",
    "    def __init__(self, x0, y0, x1, y1):\n",
    "        self.x0 = x0\n",
    "        self.y0 = y0\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "\n",
    "        self.height = abs(self.y1 - self.y0)\n",
    "        self.width = abs(self.x1 - self.x0)\n",
    "\n",
    "        self.top = None\n",
    "        self.bottom = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "        self.text = \"\"\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Cell(({self.x0}, {self.y0})-({self.x1}, {self.y1}))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373deb3a-992d-403d-8f29-326a2927bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Row:\n",
    "    def __init__(self, cells: list[Cell]) -> None:\n",
    "        self.cells = cells\n",
    "        self.length = len(cells)\n",
    "\n",
    "        self.x0 = min(cell.x0 for cell in cells)\n",
    "        self.y0 = min(cell.y0 for cell in cells)\n",
    "        self.x1 = max(cell.x1 for cell in cells)\n",
    "        self.y1 = max(cell.y1 for cell in cells)\n",
    "\n",
    "        self.text = [cell.text for cell in cells]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Row(({self.x0}, {self.y0})-({self.x1}, {self.y1}))\"\n",
    "\n",
    "\n",
    "class Column:\n",
    "    def __init__(self, cells: list[Cell]) -> None:\n",
    "        self.cells = cells\n",
    "        self.length = len(cells)\n",
    "\n",
    "        self.x0 = min(cell.x0 for cell in cells)\n",
    "        self.y0 = min(cell.y0 for cell in cells)\n",
    "        self.x1 = max(cell.x1 for cell in cells)\n",
    "        self.y1 = max(cell.y1 for cell in cells)\n",
    "\n",
    "        self.text = [cell.text for cell in cells]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Column(({self.x0}, {self.y0})-({self.x1}, {self.y1}))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d432c21-bde0-4ace-846f-93d0653425d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page:\n",
    "    def __init__(self, page) -> None:\n",
    "        self.page = page\n",
    "\n",
    "        self.page_number = self.page.page_number\n",
    "        self.height = self.page.height\n",
    "        self.width = self.page.width\n",
    "\n",
    "        self.row_grid = Page._generate_grid(self.height)\n",
    "        self.column_grid = Page._generate_grid(self.width)\n",
    "\n",
    "        self.chars = pd.DataFrame()\n",
    "        self.lines = pd.DataFrame()\n",
    "        self.edges = pd.DataFrame()\n",
    "        self.rects = pd.DataFrame()\n",
    "\n",
    "        self.cells = []\n",
    "        self.rows = []\n",
    "        self.columns = []\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Page({self.page_number}, {self.height}x{self.width})\"\n",
    "\n",
    "    def get_page_characters(self):\n",
    "        if self.chars.empty:\n",
    "            chars = self.page.chars\n",
    "\n",
    "            char_df = Page._attribute_df(\n",
    "                chars,\n",
    "                mandatory=[\"text\", \"x0\", \"y0\", \"x1\", \"y1\"],\n",
    "                selection=[\"size\", \"width\", \"height\"],\n",
    "            )\n",
    "\n",
    "            # for col in [\"x0\", \"y0\", \"x1\", \"y1\"]:\n",
    "            #     char_df[col] = char_df[col].apply(\n",
    "            #         lambda x: Page._snap_to_grid(\n",
    "            #             x, self.column_grid if col in [\"x0\", \"x1\"] else self.row_grid\n",
    "            #         )\n",
    "            #     )\n",
    "\n",
    "            self.chars = char_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        return self.chars\n",
    "\n",
    "    def get_page_lines(self):\n",
    "        if self.lines.empty:\n",
    "            lines = self.page.lines\n",
    "\n",
    "            lines_df = Page._attribute_df(\n",
    "                lines,\n",
    "                mandatory=[\"x0\", \"y0\", \"x1\", \"y1\"],\n",
    "                selection=[\"orientation\"],\n",
    "            )\n",
    "\n",
    "            lines_df[\"orientation\"] = lines_df.apply(\n",
    "                lambda row: Page._detect_orientation(\n",
    "                    row[\"x0\"], row[\"y0\"], row[\"x1\"], row[\"y1\"]\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            # for col in [\"x0\", \"y0\", \"x1\", \"y1\"]:\n",
    "            #     lines_df[col] = lines_df[col].apply(\n",
    "            #         lambda x: Page._snap_to_grid(\n",
    "            #             x, self.column_grid if col in [\"x0\", \"x1\"] else self.row_grid\n",
    "            #         )\n",
    "            #     )\n",
    "\n",
    "            self.lines = lines_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        return self.lines\n",
    "\n",
    "    def get_page_edges(self, tol: float = 2.0):\n",
    "        if self.edges.empty:\n",
    "            edges = self.page.edges\n",
    "\n",
    "            edges_df = Page._attribute_df(\n",
    "                edges,\n",
    "                mandatory=[\"x0\", \"y0\", \"x1\", \"y1\"],\n",
    "                selection=[\"orientation\"],\n",
    "            )\n",
    "\n",
    "            edges_df[\"orientation\"] = edges_df.apply(\n",
    "                lambda row: Page._detect_orientation(\n",
    "                    row[\"x0\"], row[\"y0\"], row[\"x1\"], row[\"y1\"]\n",
    "                ),\n",
    "                axis=1,\n",
    "            )\n",
    "\n",
    "            # coordinate_groups = [[\"x0\", \"y0\"], [\"x1\", \"y1\"]]\n",
    "\n",
    "            # for orientation in [\"horizontal\", \"vertical\"]:\n",
    "            #     subset = edges_df[edges_df[\"orientation\"] == orientation].copy()\n",
    "            #     indices = list(subset.index)\n",
    "\n",
    "            #     if not subset.empty:\n",
    "            #         for group in coordinate_groups:\n",
    "            #             points = np.vstack((subset[group].values))\n",
    "\n",
    "            #             clustered = Page._cluster_points(\n",
    "            #                 points,\n",
    "            #                 self.column_grid,\n",
    "            #                 self.row_grid,\n",
    "            #                 tol=tol,\n",
    "            #                 original_indices=indices,\n",
    "            #             )\n",
    "\n",
    "            #             for col in clustered.columns:\n",
    "            #                 subset_col = group[0] if col == \"x\" else group[1]\n",
    "            #                 subset.loc[indices, subset_col] = clustered[col].values\n",
    "\n",
    "            #     edges_df.loc[indices, group] = subset[group].values\n",
    "\n",
    "            # for col in [\"x0\", \"y0\", \"x1\", \"y1\"]:\n",
    "            #     edges_df[col] = edges_df[col].apply(\n",
    "            #         lambda x: Page._snap_to_grid(\n",
    "            #             x, self.column_grid if col in [\"x0\", \"x1\"] else self.row_grid\n",
    "            #         )\n",
    "            #     )\n",
    "\n",
    "            self.edges = edges_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        return self.edges\n",
    "\n",
    "    def get_page_rects(self):\n",
    "        if self.rects.empty:\n",
    "            rects = self.page.rects\n",
    "\n",
    "            rects_df = Page._attribute_df(\n",
    "                rects,\n",
    "                mandatory=[\"x0\", \"y0\", \"x1\", \"y1\"],\n",
    "                selection=[],\n",
    "            )\n",
    "\n",
    "            # for col in [\"x0\", \"y0\", \"x1\", \"y1\"]:\n",
    "            #     rects_df[col] = rects_df[col].apply(\n",
    "            #         lambda x: Page._snap_to_grid(\n",
    "            #             x, self.column_grid if col in [\"x0\", \"x1\"] else self.row_grid\n",
    "            #         )\n",
    "            #     )\n",
    "\n",
    "            self.rects = rects_df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        return self.rects\n",
    "\n",
    "    def clean_all_coords(\n",
    "        self,\n",
    "        tol: float = 3.0,\n",
    "    ):\n",
    "        groups = [[\"x0\", \"y0\"], [\"x1\", \"y1\"]]\n",
    "\n",
    "        for name in [\"chars\", \"lines\", \"edges\", \"rects\"]:\n",
    "            c = getattr(self, name)\n",
    "            if c.empty:\n",
    "                continue\n",
    "\n",
    "            for group in groups:\n",
    "                points = np.vstack((c[group].values))\n",
    "\n",
    "                db = DBSCAN(\n",
    "                    eps=tol, min_samples=1, metric=\"euclidean\", algorithm=\"kd_tree\"\n",
    "                ).fit(points)\n",
    "                labels = db.labels_\n",
    "\n",
    "                point_df = pd.DataFrame(points, columns=[\"x\", \"y\"])\n",
    "                point_df[\"cluster\"] = labels\n",
    "                centroids = point_df.groupby(\"cluster\")[[\"x\", \"y\"]].mean()\n",
    "\n",
    "                mapped_points = np.array(\n",
    "                    [centroids.loc[label].values for label in labels]\n",
    "                )\n",
    "                # new_coords = mapped_points.reshape(2, -1, 2)\n",
    "\n",
    "                for i, col in enumerate(group):\n",
    "                    c.loc[:, col] = mapped_points[:, i].astype(float)\n",
    "\n",
    "            for col in [\"x0\", \"y0\", \"x1\", \"y1\"]:\n",
    "                c[col] = c[col].apply(\n",
    "                    lambda x: Page._snap_to_grid(\n",
    "                        x, self.column_grid if col in [\"x0\", \"x1\"] else self.row_grid\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            if name in [\"lines\", \"edges\"]:\n",
    "                for _, row in c.iterrows():\n",
    "                    if row[\"orientation\"] == \"horizontal\":\n",
    "                        row[\"y1\"] = row[\"y0\"]\n",
    "                    elif row[\"orientation\"] == \"vertical\":\n",
    "                        row[\"x1\"] = row[\"x0\"]\n",
    "                    else:\n",
    "                        row[\"x0\"] = row[\"x0\"]\n",
    "                        row[\"x1\"] = row[\"x1\"]\n",
    "                        row[\"y0\"] = row[\"y0\"]\n",
    "                        row[\"y1\"] = row[\"y1\"]\n",
    "\n",
    "            c = c.drop_duplicates().reset_index(drop=True)\n",
    "            setattr(self, name, c)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def _detect_rectangles(self) -> list[dict]:\n",
    "        hor_lines = pd.concat(\n",
    "            [\n",
    "                self.lines[self.lines[\"orientation\"] == \"horizontal\"],\n",
    "                self.edges[self.edges[\"orientation\"] == \"horizontal\"],\n",
    "            ]\n",
    "        )\n",
    "        vert_lines = pd.concat(\n",
    "            [\n",
    "                self.lines[self.lines[\"orientation\"] == \"vertical\"],\n",
    "                self.edges[self.edges[\"orientation\"] == \"vertical\"],\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        intersections = Page._find_intersections(hor_lines, vert_lines)\n",
    "        rectangles = Page._detect_rectangles_from_intersections(intersections)\n",
    "\n",
    "        hierarchy = Page._assign_rectangle_hierarchy(rectangles)\n",
    "\n",
    "        l0_rectangles = [rect for rect, level in hierarchy if level == 0]\n",
    "\n",
    "        return l0_rectangles\n",
    "\n",
    "    def _initialise_cells(self, tol: float = 3.0):\n",
    "        # for _, rect in self.rects.iterrows():\n",
    "        #     self.cells.append(Cell(rect[\"x0\"], rect[\"y0\"], rect[\"x1\"], rect[\"y1\"]))\n",
    "        #     for _, char in self.chars.iterrows():\n",
    "        #         if (\n",
    "        #             char[\"x0\"] >= rect[\"x0\"] - tol\n",
    "        #             and char[\"x1\"] <= rect[\"x1\"] + tol\n",
    "        #             and char[\"y0\"] >= rect[\"y0\"] - tol\n",
    "        #             and char[\"y1\"] <= rect[\"y1\"] + tol\n",
    "        #         ):\n",
    "        #             self.cells[-1].text += char[\"text\"]\n",
    "\n",
    "        line_rectangles = self._detect_rectangles()\n",
    "\n",
    "        for _, rect in enumerate(line_rectangles):\n",
    "            x0, y0 = rect[\"top_left\"]\n",
    "            x1, y1 = rect[\"bottom_right\"]\n",
    "\n",
    "            self.cells.append(Cell(x0, y0, x1, y1))\n",
    "\n",
    "            for _, char in self.chars.iterrows():\n",
    "                if (\n",
    "                    char[\"x0\"] >= x0 - tol\n",
    "                    and char[\"x1\"] <= x1 + tol\n",
    "                    and char[\"y0\"] >= y0 - tol\n",
    "                    and char[\"y1\"] <= y1 + tol\n",
    "                ):\n",
    "                    self.cells[-1].text += char[\"text\"]\n",
    "\n",
    "        self.cells = sorted(self.cells, key=lambda x: (x.x0, -x.y0))\n",
    "\n",
    "        return self.cells\n",
    "\n",
    "    def get_cell_groups(self, tol=1.0):\n",
    "        self.rows = self._build_cell_groups(self.cells, type=\"row\", tol=tol)\n",
    "        self.columns = self._build_cell_groups(self.cells, type=\"column\", tol=tol)\n",
    "\n",
    "        return self.rows, self.columns\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_grid(dimension, resolution=1):\n",
    "        return [g for g in range(0, int(dimension), resolution)]\n",
    "\n",
    "    @staticmethod\n",
    "    def _snap_to_grid(val, grid):\n",
    "        return max([g for g in grid if g <= val], default=val)\n",
    "\n",
    "    @staticmethod\n",
    "    def _detect_orientation(x0, y0, x1, y1, tol=0.0):\n",
    "        if np.isclose(x0, x1, atol=tol):\n",
    "            return \"vertical\"\n",
    "        elif np.isclose(y0, y1, atol=tol):\n",
    "            return \"horizontal\"\n",
    "        else:\n",
    "            return \"other\"\n",
    "\n",
    "    @staticmethod\n",
    "    def _attribute_df(\n",
    "        list_dict: list[dict], mandatory: list[str], selection: list[str]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create a DataFrame from a list of dictionaries, ensuring mandatory columns are present.\n",
    "        \"\"\"\n",
    "\n",
    "        if not list_dict:\n",
    "            # Return empty DataFrame with all mandatory + selection columns as placeholders\n",
    "            columns = mandatory + selection\n",
    "            df = pd.DataFrame(columns=columns)\n",
    "            # Fill selection columns with NaN explicitly (optional here as empty)\n",
    "            for col in selection:\n",
    "                df[col] = np.nan\n",
    "            return df\n",
    "\n",
    "        df = pd.DataFrame(list_dict)\n",
    "\n",
    "        for col in mandatory:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"Mandatory column '{col}' missing in data.\")\n",
    "\n",
    "        for col in selection:\n",
    "            if col not in df.columns:\n",
    "                df[col] = np.nan\n",
    "\n",
    "        final = mandatory + selection\n",
    "\n",
    "        return df[final]\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_intersection(\n",
    "        hor_line: dict, vert_line: dict\n",
    "    ) -> tuple[float, float] | tuple[None, None]:\n",
    "        h_y = hor_line[\"y0\"]\n",
    "        h_x0, h_x1 = hor_line[\"x0\"], hor_line[\"x1\"]\n",
    "\n",
    "        v_x = vert_line[\"x0\"]\n",
    "        v_y0, v_y1 = vert_line[\"y0\"], vert_line[\"y1\"]\n",
    "\n",
    "        if (h_x0 <= v_x <= h_x1) and (v_y0 <= h_y <= v_y1):\n",
    "            return (v_x, h_y)\n",
    "        else:\n",
    "            return (None, None)\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_intersections(\n",
    "        hor_lines: pd.DataFrame, vert_lines: pd.DataFrame\n",
    "    ) -> list[dict]:\n",
    "        intersections = set()\n",
    "\n",
    "        for _, hor_line in hor_lines.iterrows():\n",
    "            for _, vert_line in vert_lines.iterrows():\n",
    "                intersection = Page._is_intersection(hor_line, vert_line)\n",
    "                if intersection[0] is not None and intersection[1] is not None:\n",
    "                    intersections.add(intersection)\n",
    "\n",
    "        return list(intersections)\n",
    "\n",
    "    @staticmethod\n",
    "    def _detect_rectangles_from_intersections(\n",
    "        intersections: list[tuple[float, float]],\n",
    "    ) -> list[dict]:\n",
    "        points_by_x = defaultdict(list)\n",
    "        points_by_y = defaultdict(list)\n",
    "\n",
    "        for point in intersections:\n",
    "            x, y = point\n",
    "            points_by_x[x].append(point)\n",
    "            points_by_y[y].append(point)\n",
    "\n",
    "        x_coords = sorted(points_by_x.keys())\n",
    "        y_coords = sorted(points_by_y.keys())\n",
    "\n",
    "        rectangles = []\n",
    "        rectangle_count = 0\n",
    "\n",
    "        for i in range(len(x_coords)):\n",
    "            for j in range(i + 1, len(x_coords)):\n",
    "                x1, x2 = x_coords[i], x_coords[j]\n",
    "\n",
    "                for k in range(len(y_coords)):\n",
    "                    for l in range(k + 1, len(y_coords)):\n",
    "                        y1, y2 = y_coords[k], y_coords[l]\n",
    "\n",
    "                        corners = [(x1, y1), (x2, y1), (x1, y2), (x2, y2)]\n",
    "\n",
    "                        if all(corner in intersections for corner in corners):\n",
    "                            rectangle = {\n",
    "                                \"top_left\": (x1, y1),\n",
    "                                \"top_right\": (x2, y1),\n",
    "                                \"bottom_left\": (x1, y2),\n",
    "                                \"bottom_right\": (x2, y2),\n",
    "                            }\n",
    "                            rectangles.append(rectangle)\n",
    "                            rectangle_count += 1\n",
    "\n",
    "        return rectangles\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_rectangle_format(rectangle: dict) -> dict:\n",
    "        min_x, min_y = rectangle[\"top_left\"]\n",
    "        max_x, max_y = rectangle[\"bottom_right\"]\n",
    "        return {\n",
    "            \"min_x\": min_x,\n",
    "            \"min_y\": min_y,\n",
    "            \"max_x\": max_x,\n",
    "            \"max_y\": max_y,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _rectangle_contains(r_outer, r_inner) -> bool:\n",
    "        \"\"\"Return True if r_outer fully contains r_inner.\n",
    "\n",
    "        Parameters:\n",
    "            r_outer: dict with keys 'min_x', 'min_y', 'max_x', 'max_y'\n",
    "            r_inner: dict with keys 'min_x', 'min_y', 'max_x', 'max_y'\n",
    "\n",
    "        Returns:\n",
    "            True if r_outer fully contains r_inner, False otherwise\n",
    "        \"\"\"\n",
    "        return (\n",
    "            r_outer[\"min_x\"] <= r_inner[\"min_x\"]\n",
    "            and r_outer[\"min_y\"] <= r_inner[\"min_y\"]\n",
    "            and r_outer[\"max_x\"] >= r_inner[\"max_x\"]\n",
    "            and r_outer[\"max_y\"] >= r_inner[\"max_y\"]\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _assign_rectangle_hierarchy(rectangles: list[dict]) -> list[dict]:\n",
    "        rects = []\n",
    "        for i, rect in enumerate(rectangles):\n",
    "            bbox = Page._convert_rectangle_format(rect)\n",
    "            bbox[\"id\"] = i\n",
    "            rects.append(bbox)\n",
    "\n",
    "        # Initialize containment map: rect_id -> list of contained rect_ids\n",
    "        contains_map = {r[\"id\"]: [] for r in rects}\n",
    "\n",
    "        # Populate contains_map\n",
    "        for r_outer in rects:\n",
    "            for r_inner in rects:\n",
    "                if r_outer[\"id\"] != r_inner[\"id\"]:\n",
    "                    if Page._rectangle_contains(r_outer, r_inner):\n",
    "                        contains_map[r_outer[\"id\"]].append(r_inner[\"id\"])\n",
    "\n",
    "        # Initialize all levels as None\n",
    "        levels = {r[\"id\"]: None for r in rects}\n",
    "\n",
    "        # Rectangles that contain no other rectangles are level 0\n",
    "        for r in rects:\n",
    "            if not contains_map[r[\"id\"]]:\n",
    "                levels[r[\"id\"]] = 0\n",
    "\n",
    "        # Iteratively assign levels\n",
    "        changed = True\n",
    "        while changed:\n",
    "            changed = False\n",
    "            for r in rects:\n",
    "                if levels[r[\"id\"]] is None:\n",
    "                    child_levels = [levels[cid] for cid in contains_map[r[\"id\"]]]\n",
    "                    # Only assign level if all child levels are assigned\n",
    "                    if None not in child_levels:\n",
    "                        levels[r[\"id\"]] = max(child_levels) + 1 if child_levels else 0\n",
    "                        changed = True\n",
    "\n",
    "        # Collect results\n",
    "        results = [(rectangles[r[\"id\"]], levels[r[\"id\"]]) for r in rects]\n",
    "        return results\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_adjacent(cell1: Cell, cell2: Cell, type=\"row\", tol=1.0):\n",
    "        if type not in [\"row\", \"column\"]:\n",
    "            raise ValueError(\"Type must be either 'row' or 'column'\")\n",
    "\n",
    "        if type == \"row\":\n",
    "            return np.isclose(cell1.x1, cell2.x0, atol=tol)\n",
    "        elif type == \"column\":\n",
    "            return np.isclose(cell1.y1, cell2.y0, atol=tol)\n",
    "        else:\n",
    "            raise ValueError(\"Type must be either 'row' or 'column'\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_cell_groups(cells: list[Cell], type=\"row\", tol=1.0):\n",
    "        if type not in [\"row\", \"column\"]:\n",
    "            raise ValueError(\"Type must be either 'row' or 'column'\")\n",
    "\n",
    "        if type == \"row\":\n",
    "            coord_col = \"y0\"\n",
    "            sort_col = \"x0\"\n",
    "        elif type == \"column\":\n",
    "            coord_col = \"x0\"\n",
    "            sort_col = \"y0\"\n",
    "        else:\n",
    "            raise ValueError(\"Type must be either 'row' or 'column'\")\n",
    "\n",
    "        cells_sorted = sorted(\n",
    "            cells, key=lambda c: (getattr(c, coord_col), getattr(c, sort_col))\n",
    "        )\n",
    "\n",
    "        groups = []\n",
    "        current_group = []\n",
    "\n",
    "        for i, cell in enumerate(cells_sorted):\n",
    "            if not current_group:\n",
    "                current_group.append(cell)\n",
    "                continue\n",
    "\n",
    "            prev_cell = current_group[-1]\n",
    "\n",
    "            same_level = (\n",
    "                abs(getattr(cell, coord_col) - getattr(prev_cell, coord_col)) < tol\n",
    "            )\n",
    "            adjacent = same_level and Page._is_adjacent(prev_cell, cell, type=type)\n",
    "\n",
    "            if same_level and adjacent:\n",
    "                current_group.append(cell)\n",
    "            else:\n",
    "                groups.append(\n",
    "                    Row(current_group) if type == \"row\" else Column(current_group)\n",
    "                )\n",
    "                current_group = [cell]\n",
    "\n",
    "        if current_group:\n",
    "            groups.append(\n",
    "                Row(current_group) if type == \"row\" else Column(current_group)\n",
    "            )\n",
    "\n",
    "        return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f629ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, path: str) -> None:\n",
    "        self.path = path\n",
    "        self.pdf = plumber.open(\n",
    "            path\n",
    "        )  # TODO: Change to an encapsulated function that handles PWD protection\n",
    "\n",
    "        self.pages = []\n",
    "        self._initialise_pages()\n",
    "\n",
    "    def _initialise_pages(self):\n",
    "        for page in self.pdf.pages:\n",
    "            self.pages.append(Page(page))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e773dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../tests/data/AKOLA JANATA COMMERCIAL COOPERATIVE BANK Statement_For_193775_012103301000485.pdf\"\n",
    "doc = Document(path)\n",
    "page = doc.pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbf82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = page.get_page_characters()\n",
    "_ = page.get_page_lines()\n",
    "_ = page.get_page_edges()\n",
    "_ = page.get_page_rects()\n",
    "\n",
    "page.clean_all_coords()\n",
    "cells = page._initialise_cells()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7615d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, columns = page.get_cell_groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc4c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rows = sorted(rows, key=lambda x: -x.y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dc5267f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length: 7, Text: [' 12-Apr-2024 ', ' 12-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024041200000230', '771', '40.00', '', '5,409.69']\n",
      "Length: 7, Text: [' 12-Apr-2024 ', ' 12-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024041200000230', '771', '5,60,000.00', '', '5,449.69']\n",
      "Length: 7, Text: [' 12-Apr-2024 ', ' 12-Apr-2024 ', 'Credit by 203307/811/', '613652', '', '2,30,000.00', '565,449.69']\n",
      "Length: 7, Text: [' 12-Apr-2024 ', ' 12-Apr-2024 ', 'BY CASH', '', '', '2,50,000.00', '335,449.69']\n",
      "Length: 7, Text: [' 12-Apr-2024 ', ' 10-Apr-2024 ', 'BY OWCLG-CTS MicrCd :444240152', '3646', '', '15,678.00', '85,449.69']\n",
      "Length: 7, Text: [' 10-Apr-2024 ', ' 10-Apr-2024 ', 'OWCTS CLE CHE WORANG ENTERY ON DT04042024', '', '40,040.00', '', '69,771.69']\n",
      "Length: 7, Text: [' 10-Apr-2024 ', ' 10-Apr-2024 ', 'BY CASH', '', '', '1,00,000.00', '109,811.69']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024040800000325', '769', '3.60', '', '9,811.69']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'CGST RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR520240408000003', '769', '3.60', '', '9,815.29']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024040800000325', '769', '40.00', '', '9,818.89']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024040800000325', '769', '9,15,000.00', '', '9,858.89']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'TR NATIONAL AUTO SERVICES', '770', '2,00,000.00', '', '924,858.89']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'Credit by 203307/811/', '613650', '', '9,00,000.00', '1,124,858.89']\n",
      "Length: 7, Text: [' 08-Apr-2024 ', ' 08-Apr-2024 ', 'BY CASH', '', '', '1,35,000.00', '224,858.89']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 04-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024040400000175', '768', '3.60', '', '89,858.89']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 04-Apr-2024 ', 'CGST RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR520240404000001', '768', '3.60', '', '89,862.49']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 04-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024040400000175', '768', '40.00', '', '89,866.09']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 04-Apr-2024 ', 'RTGS INDIAN OIL CORP AKJB0000012 BNPA0009009 AKJBR52024040400000175', '768', '6,45,000.00', '', '89,906.09']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 03-Apr-2024 ', 'BY OWCLG-CTS MicrCd :4422112', '14', '', '47,250.00', '734,906.09']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 03-Apr-2024 ', 'BY OWCLG-CTS MicrCd :444229152', '1428', '', '40,040.00', '687,656.09']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 04-Apr-2024 ', 'Credit by 203307/811/', '613648', '', '5,45,000.00', '647,616.09']\n",
      "Length: 7, Text: [' 04-Apr-2024 ', ' 04-Apr-2024 ', 'BY CASH', '', '', '1,00,000.00', '102,616.09']\n",
      "Length: 7, Text: [' 02-Apr-2024 ', ' 02-Apr-2024 ', 'TR THE SHEGAON SHREE AGRASEN CO OP CREDIT', '767', '3,50,000.00', '', '2,616.09']\n",
      "Length: 7, Text: [' 02-Apr-2024 ', ' 02-Apr-2024 ', 'BY CASH', '', '', '3,50,000.00', '352,616.09']\n",
      "Length: 7, Text: [' 01-Apr-2024 ', ' 01-Apr-2024 ', 'Opening Balance', '', '', '', '2,616.09']\n",
      "Length: 7, Text: ['Entry Date', 'Value Date', 'Description', 'Chq./Ref.No', 'Debit', 'Credit', 'Balance']\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    print(f\"Length: {row.length}, Text: {row.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a68892",
   "metadata": {},
   "outputs": [],
   "source": [
    "header_words = [\"date\",\n",
    "    \"amount\",\n",
    "    \"balance\",\n",
    "    \"description\",\n",
    "    \"particulars\",\n",
    "    \"particular\",\n",
    "    \"debit\",\n",
    "    \"credit\",\n",
    "    \"dr\",\n",
    "    \"cr\",\n",
    "    \"dr.\",\n",
    "    \"cr.\",\n",
    "    \"acct.\",\n",
    "    \"acct\",\n",
    "    \"acct no.\",\n",
    "    \"acct no\",\n",
    "    \"narration\",\n",
    "    \"closing balance\",\n",
    "    \"deposit\",\n",
    "    \"withdrawal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f307875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsiyerramillitally/Documents/projects/tables/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "header_embeddings = model.encode(header_words, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5598eab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 0, MaxSimilarity: 1.0000001192092896, MeanSimilarity: 0.2587736248970032, Index: 107\n",
      "Row: 1, MaxSimilarity: 0.7538666129112244, MeanSimilarity: 0.23244830965995789, Index: 42\n",
      "Row: 2, MaxSimilarity: 0.5474262833595276, MeanSimilarity: 0.21896512806415558, Index: 0\n",
      "Row: 3, MaxSimilarity: 0.5474262833595276, MeanSimilarity: 0.19156533479690552, Index: 0\n",
      "Row: 4, MaxSimilarity: 0.5553933382034302, MeanSimilarity: 0.2143358588218689, Index: 0\n",
      "Row: 5, MaxSimilarity: 0.6195658445358276, MeanSimilarity: 0.19015446305274963, Index: 47\n",
      "Row: 6, MaxSimilarity: 0.5553933382034302, MeanSimilarity: 0.18031474947929382, Index: 0\n",
      "Row: 7, MaxSimilarity: 0.5553933382034302, MeanSimilarity: 0.19455356895923615, Index: 0\n",
      "Row: 8, MaxSimilarity: 0.5553933382034302, MeanSimilarity: 0.1970183402299881, Index: 0\n",
      "Row: 9, MaxSimilarity: 0.5992701053619385, MeanSimilarity: 0.20173972845077515, Index: 81\n",
      "Row: 10, MaxSimilarity: 0.5553933382034302, MeanSimilarity: 0.19701595604419708, Index: 0\n",
      "Row: 11, MaxSimilarity: 0.5553933382034302, MeanSimilarity: 0.20199258625507355, Index: 0\n",
      "Row: 12, MaxSimilarity: 0.5849385261535645, MeanSimilarity: 0.20652389526367188, Index: 0\n",
      "Row: 13, MaxSimilarity: 0.6195658445358276, MeanSimilarity: 0.17806294560432434, Index: 47\n",
      "Row: 14, MaxSimilarity: 0.5849385261535645, MeanSimilarity: 0.19435465335845947, Index: 0\n",
      "Row: 15, MaxSimilarity: 0.5849385261535645, MeanSimilarity: 0.19012415409088135, Index: 0\n",
      "Row: 16, MaxSimilarity: 0.5992701053619385, MeanSimilarity: 0.1955258995294571, Index: 81\n",
      "Row: 17, MaxSimilarity: 0.5849385261535645, MeanSimilarity: 0.18802493810653687, Index: 0\n",
      "Row: 18, MaxSimilarity: 0.5849385261535645, MeanSimilarity: 0.1813240945339203, Index: 0\n",
      "Row: 19, MaxSimilarity: 0.5088348984718323, MeanSimilarity: 0.2036314755678177, Index: 101\n",
      "Row: 20, MaxSimilarity: 0.4980807900428772, MeanSimilarity: 0.19755671918392181, Index: 0\n",
      "Row: 21, MaxSimilarity: 0.5032123327255249, MeanSimilarity: 0.17449729144573212, Index: 0\n",
      "Row: 22, MaxSimilarity: 0.5032123923301697, MeanSimilarity: 0.21407833695411682, Index: 0\n",
      "Row: 23, MaxSimilarity: 0.6195658445358276, MeanSimilarity: 0.1762402355670929, Index: 47\n",
      "Row: 24, MaxSimilarity: 0.5057955384254456, MeanSimilarity: 0.17725278437137604, Index: 81\n",
      "Row: 25, MaxSimilarity: 0.5992701053619385, MeanSimilarity: 0.19012455642223358, Index: 81\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(sorted_rows):\n",
    "    row_embeddings = model.encode(row.text, convert_to_tensor=True)\n",
    "    similarities = util.pytorch_cos_sim(row_embeddings, header_embeddings)\n",
    "    max_similarity = similarities.max()\n",
    "    mean_similarity = similarities.mean()\n",
    "    max_index = similarities.argmax()\n",
    "    print(f\"Row: {i}, MaxSimilarity: {max_similarity}, MeanSimilarity: {mean_similarity}, Index: {max_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d57bdf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'#',\n",
       " 'amount',\n",
       " 'amt',\n",
       " 'available bal.',\n",
       " 'available balance',\n",
       " 'bal',\n",
       " 'balance',\n",
       " 'balance amt',\n",
       " 'beneficiary',\n",
       " 'cheque no.',\n",
       " 'cheque no/ reference no',\n",
       " 'cheque no/reference no',\n",
       " 'cheque number',\n",
       " 'cheque#',\n",
       " 'cheque/ref',\n",
       " 'cheque/ref.no.',\n",
       " 'cheque/reference#',\n",
       " 'chequeno.',\n",
       " 'chq / ref no.',\n",
       " 'chq / ref number',\n",
       " 'chq no',\n",
       " 'chq no/ref no',\n",
       " 'chq-no',\n",
       " 'chq.',\n",
       " 'chq. no.',\n",
       " 'chq./ref. number',\n",
       " 'chq./ref.no.',\n",
       " 'chq./req. number',\n",
       " 'chq.no.',\n",
       " 'chq/ref',\n",
       " 'chq/ref no',\n",
       " 'chq/ref.no',\n",
       " 'closing bal',\n",
       " 'closing balance',\n",
       " 'completion time',\n",
       " 'cr',\n",
       " 'cr amount',\n",
       " 'cr.',\n",
       " 'cr/dr',\n",
       " 'credit',\n",
       " 'credit amt',\n",
       " 'credit or debit',\n",
       " 'credit/debit',\n",
       " 'credits',\n",
       " 'credits/debits',\n",
       " 'cust ref no',\n",
       " 'customer ref',\n",
       " 'date',\n",
       " 'date id',\n",
       " 'date of transaction',\n",
       " 'dealer name',\n",
       " 'debit',\n",
       " 'debit amt',\n",
       " 'debit/credit',\n",
       " 'debits',\n",
       " 'deposit',\n",
       " 'deposit amt.',\n",
       " 'deposit(cr amount)',\n",
       " 'deposit(cr)',\n",
       " 'deposits',\n",
       " 'desc',\n",
       " 'description',\n",
       " 'details',\n",
       " 'details of transaction',\n",
       " 'dr',\n",
       " 'dr / cr',\n",
       " 'dr amount',\n",
       " 'dr.',\n",
       " 'entry date',\n",
       " 'inst no',\n",
       " 'inst number',\n",
       " 'instr no',\n",
       " 'instr. no.',\n",
       " 'instrmnt number',\n",
       " 'instrument id',\n",
       " 'instrument no',\n",
       " 'instrument number',\n",
       " 'instruments',\n",
       " 'name',\n",
       " 'narration',\n",
       " 'narrative',\n",
       " 'no.',\n",
       " 'paid in',\n",
       " 'particulars',\n",
       " 'party',\n",
       " 'payee',\n",
       " 'payment',\n",
       " 'payment date',\n",
       " 'post date',\n",
       " 'receipt',\n",
       " 'receipt no',\n",
       " 'recipient',\n",
       " 'ref',\n",
       " 'ref no',\n",
       " 'ref no./cheque no.',\n",
       " 'ref num',\n",
       " 'ref. no',\n",
       " 'ref.no',\n",
       " 'reference',\n",
       " 'remarks',\n",
       " 'running balance',\n",
       " 's.no',\n",
       " 'serial',\n",
       " 'serial number',\n",
       " 'sl. no.',\n",
       " 'sr no',\n",
       " 'sr.no.',\n",
       " 'srl',\n",
       " 'srno',\n",
       " 'total amount',\n",
       " 'total amount dr/cr',\n",
       " 'tran date',\n",
       " 'tran id',\n",
       " 'trans date',\n",
       " 'trans dt',\n",
       " 'transaction amount',\n",
       " 'transaction credit amount',\n",
       " 'transaction date',\n",
       " 'transaction debit amount',\n",
       " 'transaction description',\n",
       " 'transaction details',\n",
       " 'transaction id',\n",
       " 'transaction type',\n",
       " 'trn dt',\n",
       " 'trn. date',\n",
       " 'txn date',\n",
       " 'txn type',\n",
       " 'type',\n",
       " 'utr',\n",
       " 'utr number',\n",
       " 'val date',\n",
       " 'value',\n",
       " 'value date',\n",
       " 'value dt',\n",
       " 'withdraw(dr amount)',\n",
       " 'withdrawal',\n",
       " 'withdrawal (dr)/deposit (cr)',\n",
       " 'withdrawal amt.',\n",
       " 'withdrawals',\n",
       " 'withdrawl(dr)',\n",
       " 'withdrawn'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header_words = [\n",
    "    \"sr no\",\n",
    "    \"srno\",\n",
    "    \"sr.no.\",\n",
    "    \"serial\",\n",
    "    \"s.no\",\n",
    "    \"serial number\",\n",
    "    \"no.\",\n",
    "    \"srl\",\n",
    "    \"sl. no.\",\n",
    "    \"#\",\n",
    "    \"date\",\n",
    "    \"transaction date\",\n",
    "    \"Trans Date\",\n",
    "    \"Trans Dt\",\n",
    "    \"TRN DT\",\n",
    "    \"Txn date\",\n",
    "    \"date of transaction\",\n",
    "    \"payment date\",\n",
    "    \"entry date\",\n",
    "    \"Tran Date\",\n",
    "    \"TRN. Date\",\n",
    "    \"completion time\",\n",
    "    \"date id\",\n",
    "    \"post date\",\n",
    "    \"value date\",\n",
    "    \"val date\",\n",
    "    \"value dt\",\n",
    "    \"description\",\n",
    "    \"desc\",\n",
    "    \"particulars\",\n",
    "    \"details\",\n",
    "    \"narration\",\n",
    "    \"narrative\",\n",
    "    \"transaction details\",\n",
    "    \"remarks\",\n",
    "    \"transaction description\",\n",
    "    \"details of transaction\",\n",
    "    \"amount\",\n",
    "    \"amt\",\n",
    "    \"value\",\n",
    "    \"transaction amount\",\n",
    "    \"transaction type\",\n",
    "    \"txn type\",\n",
    "    \"type\",\n",
    "    \"credits/debits\",\n",
    "    \"cr/dr\",\n",
    "    \"credit/debit\",\n",
    "    \"credit or debit\",\n",
    "    \"type\",\n",
    "    \"dr / cr\",\n",
    "    \"Withdrawal (Dr)/Deposit (Cr)\",\n",
    "    \"DEBIT/CREDIT\",\n",
    "    \"debit\",\n",
    "    \"withdrawal\",\n",
    "    \"payment\",\n",
    "    \"dr\",\n",
    "    \"dr amount\",\n",
    "    \"dr.\",\n",
    "    \"withdrawl(dr)\",\n",
    "    \"withdrawals\",\n",
    "    \"debits\",\n",
    "    \"withdrawal amt.\",\n",
    "    \"transaction debit amount\",\n",
    "    \"debit amt\",\n",
    "    \"paid in\",\n",
    "    \"withdraw(dr amount)\",\n",
    "    \"credit\",\n",
    "    \"deposit\",\n",
    "    \"receipt\",\n",
    "    \"cr\",\n",
    "    \"cr amount\",\n",
    "    \"cr.\",\n",
    "    \"deposit(cr)\",\n",
    "    \"deposits\",\n",
    "    \"credits\",\n",
    "    \"deposit amt.\",\n",
    "    \"transaction credit amount\",\n",
    "    \"credit amt\",\n",
    "    \"withdrawn\",\n",
    "    \"deposit(cr amount)\",\n",
    "    \"beneficiary\",\n",
    "    \"payee\",\n",
    "    \"dealer name\",\n",
    "    \"name\",\n",
    "    \"party\",\n",
    "    \"recipient\",\n",
    "    \"instrument no\",\n",
    "    \"instrument number\",\n",
    "    \"inst no\",\n",
    "    \"inst number\",\n",
    "    \"instr. no.\",\n",
    "    \"instr no\",\n",
    "    \"Instruments\",\n",
    "    \"instrmnt number\",\n",
    "    \"instrument id\",\n",
    "    \"ref\",\n",
    "    \"ref no\",\n",
    "    \"reference\",\n",
    "    \"customer ref\",\n",
    "    \"cust ref no\",\n",
    "    \"transaction id\",\n",
    "    \"utr\",\n",
    "    \"cheque/ref\",\n",
    "    \"chq/ref no\",\n",
    "    \"cheque number\",\n",
    "    \"chq no\",\n",
    "    \"chq/ref\",\n",
    "    \"chq.\",\n",
    "    \"ref.no\",\n",
    "    \"chq.no.\",\n",
    "    \"chq-no\",\n",
    "    \"chq/ref.no\",\n",
    "    \"Cheque No.\",\n",
    "    \"chq./req. number\",\n",
    "    \"Cheque/Ref.No.\",\n",
    "    \"chq./ref.no.\",\n",
    "    \"chequeno.\",\n",
    "    \"chq. no.\",\n",
    "    \"chq no/ref no\",\n",
    "    \"chq./ref. number\",\n",
    "    \"ref. no\",\n",
    "    \"chq / ref number\",\n",
    "    \"cheque/Reference#\",\n",
    "    \"chq / ref no.\",\n",
    "    \"cheque#\",\n",
    "    \"receipt no\",\n",
    "    \"chq. no.\",\n",
    "    \"ref no./cheque no.\",\n",
    "    \"cheque no/ reference no\",\n",
    "    \"cheque no/reference no\",\n",
    "    \"ref num\",\n",
    "    \"utr number\",\n",
    "    \"utr\",\n",
    "    \"transaction id\",\n",
    "    \"tran id\",\n",
    "    \"instrument no\",\n",
    "    \"instrument number\",\n",
    "    \"inst no\",\n",
    "    \"inst number\",\n",
    "    \"instr. no.\",\n",
    "    \"instr no\",\n",
    "    \"Instruments\",\n",
    "    \"instrmnt number\",\n",
    "    \"instrument id\",\n",
    "    \"balance\",\n",
    "    \"bal\",\n",
    "    \"closing balance\",\n",
    "    \"running balance\",\n",
    "    \"available balance\",\n",
    "    \"available bal.\",\n",
    "    \"closing bal\",\n",
    "    \"Total Amount Dr/Cr\",\n",
    "    \"total amount\",\n",
    "    \"balance amt\",\n",
    "]\n",
    "\n",
    "set([x.lower() for x in header_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c88a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
